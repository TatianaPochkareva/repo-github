{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5beabfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40593031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pipeline in c:\\users\\pochkarenok\\anaconda3\\lib\\site-packages (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9df054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1afc5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = 'mesenger_train.csv'\n",
    "TEST_DATASET_PATH = 'mesenger_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f72c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = 'D:/task/mesenger_train.csv'\n",
    "TEST_DATASET_PATH = 'D:/task/mesenger_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c95678a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Манчестер через час играет, а я не дома (</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>RT @qukanacipr: да) а я в 2004 в жабу пришол и...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Момент из \"Мальчик и маньяк\") Ражик гладит по ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Я просто неудачик, поцарапал экран на телефоне ((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>хахаа тот день запомнился надолго) http://t.co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1\n",
       "5   5          Манчестер через час играет, а я не дома (      0\n",
       "6   6  RT @qukanacipr: да) а я в 2004 в жабу пришол и...      1\n",
       "7   7  Момент из \"Мальчик и маньяк\") Ражик гладит по ...      1\n",
       "8   8  Я просто неудачик, поцарапал экран на телефоне ((      0\n",
       "9   9  хахаа тот день запомнился надолго) http://t.co...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#тренировочный датасет\n",
    "df_train = pd.read_csv(TRAIN_DATASET_PATH)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36b7bef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22678</th>\n",
       "      <td>204145</td>\n",
       "      <td>А я знаю из-за кого такая паршивая погода была...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22679</th>\n",
       "      <td>204146</td>\n",
       "      <td>ааа.... что с Гмейлом. не ужто он умер сегодня...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22680</th>\n",
       "      <td>204147</td>\n",
       "      <td>в учебники химии написано \"Пруст Жозеф Луи\"\\nя...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22681</th>\n",
       "      <td>204148</td>\n",
       "      <td>Вот все любят,а я не люблю..как дура..говорю,ч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22682</th>\n",
       "      <td>204149</td>\n",
       "      <td>уххх спасибо дорогой Леле Евгеньевне и Штепуху...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  class\n",
       "22678  204145  А я знаю из-за кого такая паршивая погода была...      1\n",
       "22679  204146  ааа.... что с Гмейлом. не ужто он умер сегодня...      0\n",
       "22680  204147  в учебники химии написано \"Пруст Жозеф Луи\"\\nя...      1\n",
       "22681  204148  Вот все любят,а я не люблю..как дура..говорю,ч...      0\n",
       "22682  204149  уххх спасибо дорогой Леле Евгеньевне и Штепуху...      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#тестовый датасет\n",
    "df_test = pd.read_csv(TEST_DATASET_PATH)\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4e08e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((181467, 3), (22683, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5533faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    92063\n",
       "0    89404\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1434bacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'] = df_train['text'].apply(lambda x: x.lower())\n",
    "df_test['text'] = df_test['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b112e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac9b462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   101,  15668,  48143,  66620,    554,  10227, 101870,  41065,    102,\n",
      "              0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "example_text = 'Для решения задачи нужны данные'\n",
    "bert_input = tokenizer(example_text, padding='max_length', max_length=10, \n",
    "                       truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "\n",
    "print(bert_input['input_ids'])\n",
    "print(bert_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ea3d8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('еш', '##у')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_tokens[61947], tokenizer.ids_to_tokens[10227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d506ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Для решения задачи нужны данные [SEP] [PAD]\n"
     ]
    }
   ],
   "source": [
    "example_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf05ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessengerDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels):\n",
    "        self._labels = labels\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "        self._txts = [self.tokenizer(text, padding='max_length', max_length=10,\n",
    "                                     truncation=True, return_tensors=\"pt\")\n",
    "                      for text in txts]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self._txts[index], self._labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e81b77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_test = df_test['class'].values\n",
    "\n",
    "train_dataset = MessengerDataset(df_train['text'], y_train)\n",
    "test_dataset = MessengerDataset(df_test['text'], y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt, cls in train_loader:\n",
    "    print(txt.keys())\n",
    "    print(txt['input_ids'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a994aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d378804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        _, pooled_output = self.bert(input_ids=x, attention_mask=mask, return_dict=False)\n",
    "        # _, pooled_output - набор эмбеддинигов слов, эмбеддинг предложения\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.sigm(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c1e7b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c6c2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = Adam(model.linear.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62d163f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (sigm): Sigmoid()\n",
      ")\n",
      "Parameters full train: 177854978\n",
      "Parameters transfer learning: 1538\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))\n",
    "print(\"Parameters transfer learning:\", sum([param.nelement() for param in model.linear.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f55f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2836 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(2):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    model.train()\n",
    "    for train_input, train_label in tqdm(train_loader):\n",
    "        mask = train_input['attention_mask'].to(device)\n",
    "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "        train_label = train_label.to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "                \n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "                \n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model.eval()\n",
    "    total_loss_val, total_acc_val = 0.0, 0.0\n",
    "    for val_input, val_label in valid_loader:\n",
    "        val_label = val_label.to(device)\n",
    "        mask = val_input['attention_mask'].to(device)\n",
    "        input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "\n",
    "        batch_loss = criterion(output, val_label)\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "        total_acc_val += acc\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cd7fb",
   "metadata": {},
   "source": [
    "К сожалению, возможности моей компьютерной системы на этом иссякли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2e59a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
