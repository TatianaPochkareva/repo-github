{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install dialogflow gensim==3.6.0 annoy tqdm stop_words pymorphy2 python-telegram-bot==13.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  python = 3.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic_16_nlp_1.jpg' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic_16_nlp_2.jpg' width=1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic_16_nlp_3.jpg' width=1000>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.6.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from gensim==3.6.0) (1.26.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from gensim==3.6.0) (1.11.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from gensim==3.6.0) (1.16.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from gensim==3.6.0) (6.4.0)\n"
     ]
    }
   ],
   "source": [
    "!/Users/lmv/anaconda3/envs/NLP339/bin/pip3 install gensim==3.6.0 --use-pep517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.6.0\n",
      "  Using cached gensim-3.6.0-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from gensim==3.6.0) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from gensim==3.6.0) (1.11.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from gensim==3.6.0) (1.16.0)\n",
      "Collecting smart-open>=1.2.1 (from gensim==3.6.0)\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.6.0 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "!/Users/lmv/anaconda3/envs/NLP339/bin/pip3 install gensim==3.6.0 --use-pep517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting annoy\n",
      "  Using cached annoy-1.17.3-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting stop_words\n",
      "  Using cached stop_words-2018.7.23-py3-none-any.whl\n",
      "Collecting pymorphy2\n",
      "  Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Collecting python-telegram-bot==13.3\n",
      "  Using cached python_telegram_bot-13.3-py3-none-any.whl (436 kB)\n",
      "Collecting pandarallel\n",
      "  Using cached pandarallel-1.6.5-py3-none-any.whl\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: certifi in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from python-telegram-bot==13.3) (2024.2.2)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from python-telegram-bot==13.3) (6.3.3)\n",
      "Collecting APScheduler==3.6.3 (from python-telegram-bot==13.3)\n",
      "  Using cached APScheduler-3.6.3-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: pytz>=2018.6 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from python-telegram-bot==13.3) (2023.3.post1)\n",
      "Requirement already satisfied: setuptools>=0.7 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (68.2.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (1.16.0)\n",
      "Collecting tzlocal>=1.2 (from APScheduler==3.6.3->python-telegram-bot==13.3)\n",
      "  Using cached tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting docopt>=0.6 (from pymorphy2)\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting dill>=0.3.1 (from pandarallel)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas>=1 (from pandarallel)\n",
      "  Using cached pandas-2.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from pandarallel) (5.9.0)\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\n",
      "  Using cached comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipywidgets) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from pandas>=1->pandarallel) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1->pandarallel)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/lmv/anaconda3/envs/nlp339/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.0-cp39-cp39-macosx_11_0_arm64.whl (11.8 MB)\n",
      "Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: stop_words, pymorphy2-dicts-ru, docopt, dawg-python, annoy, widgetsnbextension, tzlocal, tzdata, tqdm, pymorphy2, jupyterlab-widgets, dill, comm, pandas, APScheduler, python-telegram-bot, pandarallel, ipywidgets\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.1.2\n",
      "    Uninstalling comm-0.1.2:\n",
      "      Successfully uninstalled comm-0.1.2\n",
      "Successfully installed APScheduler-3.6.3 annoy-1.17.3 comm-0.2.1 dawg-python-0.7.2 dill-0.3.8 docopt-0.6.2 ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 pandarallel-1.6.5 pandas-2.2.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 python-telegram-bot-13.3 stop_words-2018.7.23 tqdm-4.66.2 tzdata-2024.1 tzlocal-5.2 widgetsnbextension-4.0.10\n"
     ]
    }
   ],
   "source": [
    "!/Users/lmv/anaconda3/envs/NLP339/bin/pip3 install annoy tqdm stop_words pymorphy2 python-telegram-bot==13.3 pandarallel ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dialogflow in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: annoy in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (1.17.3)\n",
      "Requirement already satisfied: tqdm in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (4.66.1)\n",
      "Requirement already satisfied: stop_words in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (2018.7.23)\n",
      "Requirement already satisfied: pymorphy2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (0.9.1)\n",
      "Requirement already satisfied: python-telegram-bot==13.3 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (13.3)\n",
      "Requirement already satisfied: pandarallel in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (1.6.5)\n",
      "Requirement already satisfied: ipywidgets in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (8.1.1)\n",
      "Requirement already satisfied: certifi in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from python-telegram-bot==13.3) (2023.11.17)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from python-telegram-bot==13.3) (6.3.3)\n",
      "Requirement already satisfied: APScheduler==3.6.3 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from python-telegram-bot==13.3) (3.6.3)\n",
      "Requirement already satisfied: pytz>=2018.6 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from python-telegram-bot==13.3) (2023.3.post1)\n",
      "Requirement already satisfied: setuptools>=0.7 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (68.0.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (1.16.0)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from APScheduler==3.6.3->python-telegram-bot==13.3) (5.2)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.34.0)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dill>=0.3.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pandarallel) (0.3.7)\n",
      "Requirement already satisfied: pandas>=1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pandarallel) (2.1.3)\n",
      "Requirement already satisfied: psutil in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pandarallel) (5.9.0)\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\n",
      "  Downloading comm-0.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipywidgets) (8.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (3.20.3)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2.25.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.48.2)\n",
      "Requirement already satisfied: backcall in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (1.0.4)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pandas>=1->pandarallel) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pandas>=1->pandarallel) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pandas>=1->pandarallel) (2023.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (4.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (1.26.18)\n",
      "Requirement already satisfied: executing in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<2.0.0dev,>=1.14.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->dialogflow) (0.5.1)\n",
      "Downloading comm-0.2.1-py3-none-any.whl (7.2 kB)\n",
      "Installing collected packages: comm\n",
      "  Attempting uninstall: comm\n",
      "    Found existing installation: comm 0.1.2\n",
      "    Uninstalling comm-0.1.2:\n",
      "      Successfully uninstalled comm-0.1.2\n",
      "Successfully installed comm-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!/Users/lmv/anaconda3/envs/NLP39/bin/pip3 install annoy tqdm stop_words pymorphy2 python-telegram-bot==13.3 pandarallel ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!/Users/lmv/anaconda3/envs/NLP39/bin/pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==2.0.0\n",
      "annoy==1.17.3\n",
      "anyio @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/croot-t_zs64wy/anyio_1644482593257/work/dist\n",
      "appnope @ file:///Users/ktietz/demo/mc3/conda-bld/appnope_1629146036738/work\n",
      "APScheduler==3.6.3\n",
      "argon2-cffi @ file:///opt/conda/conda-bld/argon2-cffi_1645000214183/work\n",
      "argon2-cffi-bindings @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/croot-wbf5edig/argon2-cffi-bindings_1644845754377/work\n",
      "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\n",
      "astunparse==1.6.3\n",
      "async-lru @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_02efro5ps8/croot/async-lru_1699554529181/work\n",
      "attrs @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_224434dqzl/croot/attrs_1695717839274/work\n",
      "Babel @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_00k1rl2pus/croot/babel_1671781944131/work\n",
      "backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\n",
      "beautifulsoup4 @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_fa78jvo_0n/croot/beautifulsoup4-split_1681493044306/work\n",
      "bleach @ file:///opt/conda/conda-bld/bleach_1641577558959/work\n",
      "Brotli @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_38mvgltu8c/croots/recipe/brotli-split_1659616064542/work\n",
      "cachetools==5.3.2\n",
      "certifi @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_35eq66o3mo/croot/certifi_1700501684871/work/certifi\n",
      "cffi @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_b4nang6w_y/croot/cffi_1700254307954/work\n",
      "charset-normalizer @ file:///tmp/build/80754af9/charset-normalizer_1630003229654/work\n",
      "comm==0.2.0\n",
      "cryptography @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_905z2r5rpq/croot/cryptography_1694211573866/work\n",
      "DAWG-Python==0.7.2\n",
      "debugpy @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_563_nwtkoc/croot/debugpy_1690905063850/work\n",
      "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\n",
      "defusedxml @ file:///tmp/build/80754af9/defusedxml_1615228127516/work\n",
      "dialogflow==2.0.0\n",
      "dill==0.3.7\n",
      "docopt==0.6.2\n",
      "exceptiongroup @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_39x5d_sfd0/croot/exceptiongroup_1668714346145/work\n",
      "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\n",
      "fastjsonschema @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_43a0jaiddu/croots/recipe/python-fastjsonschema_1661368628129/work\n",
      "filelock==3.13.1\n",
      "flatbuffers==23.5.26\n",
      "fsspec==2023.12.2\n",
      "gast==0.5.4\n",
      "gensim==3.6.0\n",
      "google-api-core==1.34.0\n",
      "google-auth==2.25.1\n",
      "google-auth-oauthlib==1.2.0\n",
      "google-pasta==0.2.0\n",
      "googleapis-common-protos==1.62.0\n",
      "grpcio==1.60.0\n",
      "grpcio-status==1.48.2\n",
      "h5py==3.10.0\n",
      "huggingface-hub==0.19.4\n",
      "idna @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_771olrhiqw/croot/idna_1666125579282/work\n",
      "importlib-metadata @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_84cgjb624t/croot/importlib-metadata_1678997087058/work\n",
      "imutils==0.5.4\n",
      "ipykernel @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_98tee4lcge/croot/ipykernel_1691121640975/work\n",
      "ipython @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_6599f73fa7/croot/ipython_1694181355402/work\n",
      "ipywidgets==8.1.1\n",
      "jedi @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/croot-f1t6hma6/jedi_1644315882177/work\n",
      "Jinja2 @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_9fjgzv9ant/croot/jinja2_1666908141308/work\n",
      "joblib==1.3.2\n",
      "json5 @ file:///tmp/build/80754af9/json5_1624432770122/work\n",
      "jsonschema @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_27o3go8sqa/croot/jsonschema_1699041627313/work\n",
      "jsonschema-specifications @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_d38pclgu95/croot/jsonschema-specifications_1699032390832/work\n",
      "jupyter-events @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_14ldd9s4d0/croot/jupyter_events_1699282481406/work\n",
      "jupyter-lsp @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_ae9br5v37x/croot/jupyter-lsp-meta_1699978259353/work\n",
      "jupyter_client @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_58w2siozyz/croot/jupyter_client_1699455907045/work\n",
      "jupyter_core @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_782yoyc_98/croot/jupyter_core_1698937318631/work\n",
      "jupyter_server @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_281pz9vly5/croot/jupyter_server_1699466465530/work\n",
      "jupyter_server_terminals @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_e7ryd60iuw/croot/jupyter_server_terminals_1686870731283/work\n",
      "jupyterlab @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_93_oag751q/croot/jupyterlab_1700518288149/work\n",
      "jupyterlab-pygments @ file:///tmp/build/80754af9/jupyterlab_pygments_1601490720602/work\n",
      "jupyterlab-widgets==3.0.9\n",
      "jupyterlab_server @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_315a64u22w/croot/jupyterlab_server_1699555438434/work\n",
      "keras==2.15.0\n",
      "libclang==16.0.6\n",
      "Markdown==3.5.1\n",
      "MarkupSafe @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_12c133f5-0720-4727-9c18-599a3af825723lzwham3/croots/recipe/markupsafe_1654597866058/work\n",
      "matplotlib-inline @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_f6fdc0hldi/croots/recipe/matplotlib-inline_1662014472341/work\n",
      "mistune @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_17ya6k1sbs/croots/recipe/mistune_1661496228719/work\n",
      "ml-dtypes==0.2.0\n",
      "MouseInfo==0.1.3\n",
      "nbclient @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_626hpwnurm/croot/nbclient_1698934218848/work\n",
      "nbconvert @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_caxv2emy33/croot/nbconvert_1699022756174/work\n",
      "nbformat @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_cbnf5nccgk/croot/nbformat_1694616744196/work\n",
      "nest-asyncio @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_6b_e0dr4lw/croot/nest-asyncio_1672387130036/work\n",
      "notebook @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d3ves7gv_b/croot/notebook_1700582112788/work\n",
      "notebook_shim @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d6_ze10f45/croot/notebook-shim_1699455897525/work\n",
      "numpy @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_c0s16d4ba1/croot/numpy_and_numpy_base_1701295077539/work/dist/numpy-1.26.2-cp39-cp39-macosx_11_0_arm64.whl#sha256=0da8b60bd6323ba8e28538660c7ef0fb6ac9bf54bdee4bbabda5e78e03eda9c2\n",
      "oauthlib==3.2.2\n",
      "opt-einsum==3.3.0\n",
      "overrides @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_70s80guh9g/croot/overrides_1699371144462/work\n",
      "packaging @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_6dm6d4jd_t/croot/packaging_1693575176524/work\n",
      "pandarallel==1.6.5\n",
      "pandas==2.1.3\n",
      "pandocfilters @ file:///opt/conda/conda-bld/pandocfilters_1643405455980/work\n",
      "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\n",
      "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\n",
      "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\n",
      "pillow==10.2.0\n",
      "platformdirs @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_a8u4fy8k9o/croot/platformdirs_1692205661656/work\n",
      "prometheus-client @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_25sgeyk0j5/croots/recipe/prometheus_client_1659455103277/work\n",
      "prompt-toolkit @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_0blbsngvis/croot/prompt-toolkit_1672387317724/work\n",
      "protobuf==3.20.3\n",
      "psutil @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1310b568-21f4-4cb0-b0e3-2f3d31e39728k9coaga5/croots/recipe/psutil_1656431280844/work\n",
      "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\n",
      "pyasn1==0.5.1\n",
      "pyasn1-modules==0.3.0\n",
      "PyAutoGUI==0.9.54\n",
      "pycparser @ file:///tmp/build/80754af9/pycparser_1636541352034/work\n",
      "PyGetWindow==0.0.9\n",
      "Pygments @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_29bs9f_dh9/croot/pygments_1684279974747/work\n",
      "pymorphy2==0.9.1\n",
      "pymorphy2-dicts-ru==2.4.417127.4579844\n",
      "PyMsgBox==1.0.9\n",
      "pyobjc==10.1\n",
      "pyobjc-core==10.1\n",
      "pyobjc-framework-Accessibility==10.1\n",
      "pyobjc-framework-Accounts==10.1\n",
      "pyobjc-framework-AddressBook==10.1\n",
      "pyobjc-framework-AdServices==10.1\n",
      "pyobjc-framework-AdSupport==10.1\n",
      "pyobjc-framework-AppleScriptKit==10.1\n",
      "pyobjc-framework-AppleScriptObjC==10.1\n",
      "pyobjc-framework-ApplicationServices==10.1\n",
      "pyobjc-framework-AppTrackingTransparency==10.1\n",
      "pyobjc-framework-AudioVideoBridging==10.1\n",
      "pyobjc-framework-AuthenticationServices==10.1\n",
      "pyobjc-framework-AutomaticAssessmentConfiguration==10.1\n",
      "pyobjc-framework-Automator==10.1\n",
      "pyobjc-framework-AVFoundation==10.1\n",
      "pyobjc-framework-AVKit==10.1\n",
      "pyobjc-framework-AVRouting==10.1\n",
      "pyobjc-framework-BackgroundAssets==10.1\n",
      "pyobjc-framework-BusinessChat==10.1\n",
      "pyobjc-framework-CalendarStore==10.1\n",
      "pyobjc-framework-CallKit==10.1\n",
      "pyobjc-framework-CFNetwork==10.1\n",
      "pyobjc-framework-Cinematic==10.1\n",
      "pyobjc-framework-ClassKit==10.1\n",
      "pyobjc-framework-CloudKit==10.1\n",
      "pyobjc-framework-Cocoa==10.1\n",
      "pyobjc-framework-Collaboration==10.1\n",
      "pyobjc-framework-ColorSync==10.1\n",
      "pyobjc-framework-Contacts==10.1\n",
      "pyobjc-framework-ContactsUI==10.1\n",
      "pyobjc-framework-CoreAudio==10.1\n",
      "pyobjc-framework-CoreAudioKit==10.1\n",
      "pyobjc-framework-CoreBluetooth==10.1\n",
      "pyobjc-framework-CoreData==10.1\n",
      "pyobjc-framework-CoreHaptics==10.1\n",
      "pyobjc-framework-CoreLocation==10.1\n",
      "pyobjc-framework-CoreMedia==10.1\n",
      "pyobjc-framework-CoreMediaIO==10.1\n",
      "pyobjc-framework-CoreMIDI==10.1\n",
      "pyobjc-framework-CoreML==10.1\n",
      "pyobjc-framework-CoreMotion==10.1\n",
      "pyobjc-framework-CoreServices==10.1\n",
      "pyobjc-framework-CoreSpotlight==10.1\n",
      "pyobjc-framework-CoreText==10.1\n",
      "pyobjc-framework-CoreWLAN==10.1\n",
      "pyobjc-framework-CryptoTokenKit==10.1\n",
      "pyobjc-framework-DataDetection==10.1\n",
      "pyobjc-framework-DeviceCheck==10.1\n",
      "pyobjc-framework-DictionaryServices==10.1\n",
      "pyobjc-framework-DiscRecording==10.1\n",
      "pyobjc-framework-DiscRecordingUI==10.1\n",
      "pyobjc-framework-DiskArbitration==10.1\n",
      "pyobjc-framework-DVDPlayback==10.1\n",
      "pyobjc-framework-EventKit==10.1\n",
      "pyobjc-framework-ExceptionHandling==10.1\n",
      "pyobjc-framework-ExecutionPolicy==10.1\n",
      "pyobjc-framework-ExtensionKit==10.1\n",
      "pyobjc-framework-ExternalAccessory==10.1\n",
      "pyobjc-framework-FileProvider==10.1\n",
      "pyobjc-framework-FileProviderUI==10.1\n",
      "pyobjc-framework-FinderSync==10.1\n",
      "pyobjc-framework-FSEvents==10.1\n",
      "pyobjc-framework-GameCenter==10.1\n",
      "pyobjc-framework-GameController==10.1\n",
      "pyobjc-framework-GameKit==10.1\n",
      "pyobjc-framework-GameplayKit==10.1\n",
      "pyobjc-framework-HealthKit==10.1\n",
      "pyobjc-framework-ImageCaptureCore==10.1\n",
      "pyobjc-framework-InputMethodKit==10.1\n",
      "pyobjc-framework-InstallerPlugins==10.1\n",
      "pyobjc-framework-InstantMessage==10.1\n",
      "pyobjc-framework-Intents==10.1\n",
      "pyobjc-framework-IntentsUI==10.1\n",
      "pyobjc-framework-IOBluetooth==10.1\n",
      "pyobjc-framework-IOBluetoothUI==10.1\n",
      "pyobjc-framework-IOSurface==10.1\n",
      "pyobjc-framework-iTunesLibrary==10.1\n",
      "pyobjc-framework-KernelManagement==10.1\n",
      "pyobjc-framework-LatentSemanticMapping==10.1\n",
      "pyobjc-framework-LaunchServices==10.1\n",
      "pyobjc-framework-libdispatch==10.1\n",
      "pyobjc-framework-libxpc==10.1\n",
      "pyobjc-framework-LinkPresentation==10.1\n",
      "pyobjc-framework-LocalAuthentication==10.1\n",
      "pyobjc-framework-LocalAuthenticationEmbeddedUI==10.1\n",
      "pyobjc-framework-MailKit==10.1\n",
      "pyobjc-framework-MapKit==10.1\n",
      "pyobjc-framework-MediaAccessibility==10.1\n",
      "pyobjc-framework-MediaLibrary==10.1\n",
      "pyobjc-framework-MediaPlayer==10.1\n",
      "pyobjc-framework-MediaToolbox==10.1\n",
      "pyobjc-framework-Metal==10.1\n",
      "pyobjc-framework-MetalFX==10.1\n",
      "pyobjc-framework-MetalKit==10.1\n",
      "pyobjc-framework-MetalPerformanceShaders==10.1\n",
      "pyobjc-framework-MetalPerformanceShadersGraph==10.1\n",
      "pyobjc-framework-MetricKit==10.1\n",
      "pyobjc-framework-MLCompute==10.1\n",
      "pyobjc-framework-ModelIO==10.1\n",
      "pyobjc-framework-MultipeerConnectivity==10.1\n",
      "pyobjc-framework-NaturalLanguage==10.1\n",
      "pyobjc-framework-NetFS==10.1\n",
      "pyobjc-framework-Network==10.1\n",
      "pyobjc-framework-NetworkExtension==10.1\n",
      "pyobjc-framework-NotificationCenter==10.1\n",
      "pyobjc-framework-OpenDirectory==10.1\n",
      "pyobjc-framework-OSAKit==10.1\n",
      "pyobjc-framework-OSLog==10.1\n",
      "pyobjc-framework-PassKit==10.1\n",
      "pyobjc-framework-PencilKit==10.1\n",
      "pyobjc-framework-PHASE==10.1\n",
      "pyobjc-framework-Photos==10.1\n",
      "pyobjc-framework-PhotosUI==10.1\n",
      "pyobjc-framework-PreferencePanes==10.1\n",
      "pyobjc-framework-PushKit==10.1\n",
      "pyobjc-framework-Quartz==10.1\n",
      "pyobjc-framework-QuickLookThumbnailing==10.1\n",
      "pyobjc-framework-ReplayKit==10.1\n",
      "pyobjc-framework-SafariServices==10.1\n",
      "pyobjc-framework-SafetyKit==10.1\n",
      "pyobjc-framework-SceneKit==10.1\n",
      "pyobjc-framework-ScreenCaptureKit==10.1\n",
      "pyobjc-framework-ScreenSaver==10.1\n",
      "pyobjc-framework-ScreenTime==10.1\n",
      "pyobjc-framework-ScriptingBridge==10.1\n",
      "pyobjc-framework-SearchKit==10.1\n",
      "pyobjc-framework-Security==10.1\n",
      "pyobjc-framework-SecurityFoundation==10.1\n",
      "pyobjc-framework-SecurityInterface==10.1\n",
      "pyobjc-framework-SensitiveContentAnalysis==10.1\n",
      "pyobjc-framework-ServiceManagement==10.1\n",
      "pyobjc-framework-SharedWithYou==10.1\n",
      "pyobjc-framework-SharedWithYouCore==10.1\n",
      "pyobjc-framework-ShazamKit==10.1\n",
      "pyobjc-framework-Social==10.1\n",
      "pyobjc-framework-SoundAnalysis==10.1\n",
      "pyobjc-framework-Speech==10.1\n",
      "pyobjc-framework-SpriteKit==10.1\n",
      "pyobjc-framework-StoreKit==10.1\n",
      "pyobjc-framework-Symbols==10.1\n",
      "pyobjc-framework-SyncServices==10.1\n",
      "pyobjc-framework-SystemConfiguration==10.1\n",
      "pyobjc-framework-SystemExtensions==10.1\n",
      "pyobjc-framework-ThreadNetwork==10.1\n",
      "pyobjc-framework-UniformTypeIdentifiers==10.1\n",
      "pyobjc-framework-UserNotifications==10.1\n",
      "pyobjc-framework-UserNotificationsUI==10.1\n",
      "pyobjc-framework-VideoSubscriberAccount==10.1\n",
      "pyobjc-framework-VideoToolbox==10.1\n",
      "pyobjc-framework-Virtualization==10.1\n",
      "pyobjc-framework-Vision==10.1\n",
      "pyobjc-framework-WebKit==10.1\n",
      "pyOpenSSL @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_b8whqav6qm/croot/pyopenssl_1690223428943/work\n",
      "pyperclip==1.8.2\n",
      "PyRect==0.2.0\n",
      "PyScreeze==0.1.30\n",
      "PySocks @ file:///Users/ktietz/Code/oss/ci_pkgs/pysocks_1626781349491/work\n",
      "python-dateutil @ file:///tmp/build/80754af9/python-dateutil_1626374649649/work\n",
      "python-json-logger @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_c3baq2ko4j/croot/python-json-logger_1683823815343/work\n",
      "python-telegram-bot==13.3\n",
      "pytweening==1.0.7\n",
      "pytz @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_6btwyyj8a1/croot/pytz_1695131592184/work\n",
      "PyYAML @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_a8_sdgulmz/croot/pyyaml_1698096054705/work\n",
      "pyzmq @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_23n9bfwjq5/croot/pyzmq_1686601381911/work\n",
      "referencing @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_5cz64gsx70/croot/referencing_1699012046031/work\n",
      "regex==2023.10.3\n",
      "requests @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_54zi68h2nb/croot/requests_1690400233316/work\n",
      "requests-oauthlib==1.3.1\n",
      "rfc3339-validator @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_76ae5cu30h/croot/rfc3339-validator_1683077051957/work\n",
      "rfc3986-validator @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d0l5zd97kt/croot/rfc3986-validator_1683058998431/work\n",
      "rpds-py @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_f8jkozoefm/croot/rpds-py_1698945944860/work\n",
      "rsa==4.9\n",
      "rubicon-objc==0.4.7\n",
      "safetensors==0.4.1\n",
      "scikit-learn==1.3.2\n",
      "scipy==1.11.4\n",
      "Send2Trash @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_5b31f0zzlv/croot/send2trash_1699371144121/work\n",
      "six @ file:///tmp/build/80754af9/six_1644875935023/work\n",
      "smart-open==6.4.0\n",
      "sniffio @ file:///Users/ktietz/demo/mc3/conda-bld/sniffio_1629145892482/work\n",
      "soupsieve @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_9798xzs_03/croot/soupsieve_1696347567192/work\n",
      "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\n",
      "stop-words==2018.7.23\n",
      "tensorboard==2.15.1\n",
      "tensorboard-data-server==0.7.2\n",
      "tensorflow==2.15.0\n",
      "tensorflow-estimator==2.15.0\n",
      "tensorflow-io-gcs-filesystem==0.34.0\n",
      "tensorflow-macos==2.15.0\n",
      "termcolor==2.4.0\n",
      "terminado @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_fcfvyc0an2/croot/terminado_1671751835701/work\n",
      "threadpoolctl==3.2.0\n",
      "tinycss2 @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_fcw5_i306t/croot/tinycss2_1668168825117/work\n",
      "tokenizers==0.15.0\n",
      "tomli @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d0e5ffbf-5cf1-45be-8693-c5dff8108a2awhthtjlq/croots/recipe/tomli_1657175508477/work\n",
      "tornado @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_3a5nrn2jeh/croot/tornado_1696936974091/work\n",
      "tqdm==4.66.1\n",
      "traitlets @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_6301rd5qbe/croot/traitlets_1671143894285/work\n",
      "transformers==4.36.0\n",
      "typing_extensions @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_1fdywrbp_3/croot/typing_extensions_1690297474455/work\n",
      "tzdata==2023.3\n",
      "tzlocal==5.2\n",
      "urllib3 @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_068obtb882/croot/urllib3_1698257558009/work\n",
      "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
      "webencodings==0.5.1\n",
      "websocket-client @ file:///Users/ktietz/demo/mc3/conda-bld/websocket-client_1629357070578/work\n",
      "Werkzeug==3.0.1\n",
      "widgetsnbextension==4.0.9\n",
      "wrapt==1.14.1\n",
      "zipp @ file:///private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_8cv5zqoqed/croot/zipp_1672387131277/work\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.   RESTART KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Том в устройстве C не имеет метки.\n",
      " Серийный номер тома: D65B-DE15\n",
      "\n",
      " Содержимое папки C:\\Users\\Zoran\\Обработка текста\n",
      "\n",
      "14.03.2024  14:31    <DIR>          .\n",
      "14.03.2024  14:31    <DIR>          ..\n",
      "14.03.2024  14:29    <DIR>          .ipynb_checkpoints\n",
      "04.03.2024  14:07               659 2.0.1\n",
      "15.03.2022  16:19            95 893 allennlp-checkpoint.ipynb\n",
      "24.02.2024  15:57           245 793 BigARTM_L4.ipynb\n",
      "29.02.2024  21:28           482 102 colab_text_classification_part1_LMV.ipynb\n",
      "27.02.2024  17:21    <DIR>          Collection5\n",
      "27.02.2024  17:21         1 899 530 collection5.zip\n",
      "27.02.2024  16:13    <DIR>          datasets\n",
      "07.03.2024  23:31    <DIR>          DZ1\n",
      "07.03.2024  11:20           397 168 evgenyi_onegin.txt\n",
      "22.02.2024  17:59             1 751 hw4.txt\n",
      "14.03.2024  14:30           138 221 lesson_15_LMV_10.ipynb\n",
      "14.03.2024  14:29           114 271 lesson_15_LMV_14.ipynb\n",
      "20.02.2024  01:58           651 601 lesson_1_NLP.ipynb\n",
      "20.02.2024  01:52            50 934 lesson_2.ipynb\n",
      "24.02.2024  16:28           252 359 Lesson_2_MOB.ipynb\n",
      "12.03.2024  14:18            37 977 lesson_3.ipynb\n",
      "04.03.2024  15:32    <DIR>          logs\n",
      "14.03.2024  14:31           114 385 My_chat_bot_NLP_PTA.ipynb\n",
      "27.02.2024  14:40         1 092 750 NER-1_LMV.ipynb\n",
      "27.02.2024  14:41           330 028 NER-2_LMV.ipynb\n",
      "12.03.2024  14:28            62 202 NLP шаблоны.ipynb\n",
      "04.03.2024  12:46           200 252 NLP_LMV_CNN_7.ipynb\n",
      "11.03.2024  14:49     1 847 850 502 Otvety.txt\n",
      "24.02.2024  15:56            12 586 parse_rospotrebnadzor_L4.ipynb\n",
      "14.03.2024  14:17    <DIR>          png\n",
      "18.02.2024  15:23            49 652 Pre-processing DATA.ipynb\n",
      "15.02.2024  13:06            98 125 sem2.ipynb\n",
      "14.03.2024  13:28           862 704 text_generation.ipynb\n",
      "24.02.2024  15:56           641 165 topic_modeling_L4.ipynb\n",
      "30.01.2021  00:30        68 802 655 train.csv\n",
      "30.01.2021  00:30         2 941 524 train_case2.csv\n",
      "12.05.2022  10:48            21 316 translate-colab.ipynb\n",
      "25.02.2024  00:16            98 666 tweets.dict\n",
      "25.02.2024  00:16         2 221 530 tweets.model\n",
      "25.02.2024  00:16           197 387 tweets.model.index\n",
      "29.02.2024  18:25       329 722 594 video NLP классификация текста.mp4\n",
      "30.01.2021  00:30           287 514 webinar3.ipynb\n",
      "10.02.2023  13:04    <DIR>          _11_16_\n",
      "11.02.2023  17:20    <DIR>          _1_16_\n",
      "09.02.2024  15:23        19 550 484 _1_16_v2.zip\n",
      "11.02.2024  14:18    <DIR>          __MACOSX\n",
      "14.03.2024  14:14    <DIR>          Пример разбора ДЗ_NLP\n",
      "14.03.2024  13:29            96 340 Пример_разбора_ДЗ_NLP_09_checkpoints.ipynb\n",
      "14.03.2024  13:29           873 998 Пример_разбора_ДЗ_NLP_09_GRU.ipynb\n",
      "14.03.2024  13:29            48 412 Пример_разбора_ДЗ_NLP_09_LSTM.ipynb\n",
      "08.02.2024  23:00            25 734 СписокДЗ_NLP.docx\n",
      "09.02.2024  15:37         2 921 248 Урок-1 (1).pptx\n",
      "26.10.2020  23:26            83 923 ШБД Тюнинг_модели_отбор_фичей.ipynb\n",
      "              39 файлов  2 283 575 935 байт\n",
      "              12 папок  95 554 338 816 байт свободно\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Том в устройстве C не имеет метки.\n",
      " Серийный номер тома: D65B-DE15\n",
      "\n",
      " Содержимое папки C:\\Users\\Zoran\\Обработка текста\n",
      "\n",
      "14.03.2024  14:39    <DIR>          .\n",
      "14.03.2024  14:39    <DIR>          ..\n",
      "14.03.2024  14:29    <DIR>          .ipynb_checkpoints\n",
      "04.03.2024  14:07               659 2.0.1\n",
      "15.03.2022  16:19            95 893 allennlp-checkpoint.ipynb\n",
      "24.02.2024  15:57           245 793 BigARTM_L4.ipynb\n",
      "29.02.2024  21:28           482 102 colab_text_classification_part1_LMV.ipynb\n",
      "27.02.2024  17:21    <DIR>          Collection5\n",
      "27.02.2024  17:21         1 899 530 collection5.zip\n",
      "27.02.2024  16:13    <DIR>          datasets\n",
      "07.03.2024  23:31    <DIR>          DZ1\n",
      "07.03.2024  11:20           397 168 evgenyi_onegin.txt\n",
      "22.02.2024  17:59             1 751 hw4.txt\n",
      "14.03.2024  14:30           138 221 lesson_15_LMV_10.ipynb\n",
      "14.03.2024  14:29           114 271 lesson_15_LMV_14.ipynb\n",
      "20.02.2024  01:58           651 601 lesson_1_NLP.ipynb\n",
      "20.02.2024  01:52            50 934 lesson_2.ipynb\n",
      "24.02.2024  16:28           252 359 Lesson_2_MOB.ipynb\n",
      "12.03.2024  14:18            37 977 lesson_3.ipynb\n",
      "04.03.2024  15:32    <DIR>          logs\n",
      "14.03.2024  14:39           117 538 My_chat_bot_NLP_PTA.ipynb\n",
      "27.02.2024  14:40         1 092 750 NER-1_LMV.ipynb\n",
      "27.02.2024  14:41           330 028 NER-2_LMV.ipynb\n",
      "12.03.2024  14:28            62 202 NLP шаблоны.ipynb\n",
      "04.03.2024  12:46           200 252 NLP_LMV_CNN_7.ipynb\n",
      "11.03.2024  14:49     1 847 850 502 Otvety.txt\n",
      "24.02.2024  15:56            12 586 parse_rospotrebnadzor_L4.ipynb\n",
      "14.03.2024  14:17    <DIR>          png\n",
      "18.02.2024  15:23            49 652 Pre-processing DATA.ipynb\n",
      "14.03.2024  14:31                 0 prepared_answers.txt\n",
      "15.02.2024  13:06            98 125 sem2.ipynb\n",
      "14.03.2024  13:28           862 704 text_generation.ipynb\n",
      "24.02.2024  15:56           641 165 topic_modeling_L4.ipynb\n",
      "30.01.2021  00:30        68 802 655 train.csv\n",
      "30.01.2021  00:30         2 941 524 train_case2.csv\n",
      "12.05.2022  10:48            21 316 translate-colab.ipynb\n",
      "25.02.2024  00:16            98 666 tweets.dict\n",
      "25.02.2024  00:16         2 221 530 tweets.model\n",
      "25.02.2024  00:16           197 387 tweets.model.index\n",
      "29.02.2024  18:25       329 722 594 video NLP классификация текста.mp4\n",
      "30.01.2021  00:30           287 514 webinar3.ipynb\n",
      "10.02.2023  13:04    <DIR>          _11_16_\n",
      "11.02.2023  17:20    <DIR>          _1_16_\n",
      "09.02.2024  15:23        19 550 484 _1_16_v2.zip\n",
      "11.02.2024  14:18    <DIR>          __MACOSX\n",
      "14.03.2024  14:14    <DIR>          Пример разбора ДЗ_NLP\n",
      "14.03.2024  13:29            96 340 Пример_разбора_ДЗ_NLP_09_checkpoints.ipynb\n",
      "14.03.2024  13:29           873 998 Пример_разбора_ДЗ_NLP_09_GRU.ipynb\n",
      "14.03.2024  13:29            48 412 Пример_разбора_ДЗ_NLP_09_LSTM.ipynb\n",
      "08.02.2024  23:00            25 734 СписокДЗ_NLP.docx\n",
      "09.02.2024  15:37         2 921 248 Урок-1 (1).pptx\n",
      "26.10.2020  23:26            83 923 ШБД Тюнинг_модели_отбор_фичей.ipynb\n",
      "              40 файлов  2 283 579 088 байт\n",
      "              12 папок  95 315 202 048 байт свободно\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xAhRcgdAVJzn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zoran\\AppData\\Local\\Temp\\ipykernel_9068\\2549904051.py:11: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from telegram.ext  import Updater, CommandHandler, MessageHandler, Filters\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "import annoy\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "    \n",
    "tqdm.pandas()\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmap\n",
    "import re\n",
    "\n",
    "def get_num_lines(file_path):\n",
    "    fp = open(file_path, \"r+\")\n",
    "    buf = mmap.mmap(fp.fileno(), 0)\n",
    "    lines = 0\n",
    "    while buf.readline():\n",
    "        lines += 1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = get_num_lines(\"Otvety.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7550926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_lines(\"Otvety.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать файл Otvety.txt по ссылке  (1,7G)\n",
    "# https://drive.google.com/file/d/1DQL9ybca4USImUDaxxHmkIZNmClKBtKG/view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё необходимо для разговорной модели скачать файл **Otvety.txt** (1,7G) по ссылке:\n",
    "\n",
    "https://drive.google.com/file/d/1DQL9ybca4USImUDaxxHmkIZNmClKBtKG/view\n",
    "\n",
    "Также необходимо для продуктовой модели скачать файл **ProductsDataset.csv** (15,7M) по ссылке:\n",
    "\n",
    "https://gbcdn.mrgcdn.ru/uploads/asset/5209459/attachment/1b2f5aa57ff77e7c2d2ee26ceb09eb9e.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JBnSQav-VJz6"
   },
   "outputs": [],
   "source": [
    "# Преобразование файла вопросов-ответов в строчный вид\n",
    "if not os.path.isfile('prepared_answers.txt'):\n",
    "    \n",
    "    question = None\n",
    "    written = False\n",
    "    \n",
    "    with open(\"prepared_answers.txt\", \"w\", encoding='utf-8') as fout:  \n",
    "        with open(\"Otvety.txt\", \"r\", encoding='utf-8') as fin:\n",
    "            for line in tqdm(fin):\n",
    "                if line.startswith(\"---\"):\n",
    "                    written = False\n",
    "                    continue\n",
    "                if not written and question is not None:\n",
    "                    fout.write(question.replace(\"\\t\", \" \").strip() + \"===\" + line.replace(\"\\t\", \" \"))\n",
    "                    written = True\n",
    "                    question = None\n",
    "                    continue\n",
    "                if not written:\n",
    "                    question = line.strip()\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qNovia_FVJz7"
   },
   "outputs": [],
   "source": [
    "# Препроцессинг текста\n",
    "def preprocess_txt(line):\n",
    "    spls = \"\".join(i for i in line.strip() if i not in exclude).split()\n",
    "    spls = [morpher.parse(i.lower())[0].normal_form for i in spls]\n",
    "    spls = [i for i in spls if i not in sw and i != \"\"]\n",
    "    return spls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "f32db27df42f4863a58d2d9996f088e3"
     ]
    },
    "id": "uvwpdubYVJz8",
    "outputId": "83dd0de8-4106-4dbc-c584-61c1a23cb9bd"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot mmap an empty file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m file_path_to \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOtvety2.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(file_path_to):\n\u001b[1;32m---> 15\u001b[0m     N \u001b[38;5;241m=\u001b[39m \u001b[43mget_num_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path_from\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path_to, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fileto:\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path_from) \u001b[38;5;28;01mas\u001b[39;00m filefrom:\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mget_num_lines\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_num_lines\u001b[39m(file_path):\n\u001b[0;32m      5\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43mmmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mreadline():\n",
      "\u001b[1;31mValueError\u001b[0m: cannot mmap an empty file"
     ]
    }
   ],
   "source": [
    "# Обработка текста\n",
    "\n",
    "sentences = []\n",
    "morpher = MorphAnalyzer()\n",
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(string.punctuation)\n",
    "exclude = {}\n",
    "c = 0\n",
    "\n",
    "file_path_from = 'prepared_answers.txt'\n",
    "file_path_to = 'Otvety2.txt'\n",
    "\n",
    "if not os.path.isfile(file_path_to):\n",
    "    \n",
    "    N = get_num_lines(file_path_from)\n",
    "    with open(file_path_to, mode = 'w') as fileto:\n",
    "        with open(file_path_from) as filefrom:\n",
    "            for k in tqdm(range(N)):\n",
    "                line = filefrom.readline()\n",
    "                if line == '': break\n",
    "                spls = preprocess_txt(line)\n",
    "                sentences.append(spls)\n",
    "                c += 1\n",
    "                if c > 50_000:\n",
    "                    break\n",
    "                fileto.write(' '.join(spls)+'\\n')\n",
    "    filefrom.close()\n",
    "    fileto.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3adbfdb88c24ff19611eff607db9bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузить результат\n",
    "\n",
    "sentences = []\n",
    "\n",
    "file_path_from = 'Otvety2.txt'\n",
    "if os.path.isfile(file_path_from):  \n",
    "    N = get_num_lines(file_path_from) \n",
    "    with open(file_path_to, mode = 'r') as filefrom:\n",
    "        for k in tqdm(range(N)):\n",
    "            line = filefrom.readline()\n",
    "            if line == '': break\n",
    "            sentences.append(line.split())\n",
    "    filefrom.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1542',\n",
       " '1548',\n",
       " '1588',\n",
       " '16ть',\n",
       " '1890—1907liul',\n",
       " '1898',\n",
       " '18мкака',\n",
       " '1914',\n",
       " '1мми',\n",
       " '2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = []\n",
    "_ = [vec.extend(x)  for x in sentences[:100]]\n",
    "vec = list(set(vec))\n",
    "vec.sort()\n",
    "vec[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['text'] = value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['парень',\n",
       "  'относиться',\n",
       "  'цветной',\n",
       "  'линза',\n",
       "  'девушка',\n",
       "  'зелёный',\n",
       "  'глаз',\n",
       "  'голубой',\n",
       "  'вобщий',\n",
       "  'прикалывать',\n",
       "  'тема'],\n",
       " ['делать',\n",
       "  'найти',\n",
       "  '2',\n",
       "  'миллион',\n",
       "  'рубль',\n",
       "  'счастие',\n",
       "  'свалиться',\n",
       "  'хороший',\n",
       "  'пойти',\n",
       "  'милиция',\n",
       "  'заявить',\n",
       "  'находка',\n",
       "  'деньга',\n",
       "  'тероть',\n",
       "  'самый',\n",
       "  'интересный',\n",
       "  'неприменный',\n",
       "  'искать',\n",
       "  'поверьте',\n",
       "  'найти',\n",
       "  'видеть',\n",
       "  'подобный',\n",
       "  'нарваться',\n",
       "  'бабушка',\n",
       "  'помочий',\n",
       "  'внук',\n",
       "  'покупка',\n",
       "  'квартира',\n",
       "  'бандит',\n",
       "  'разговаривать',\n",
       "  'иначе',\n",
       "  'бабушка',\n",
       "  'милиция',\n",
       "  'выбор',\n",
       "  'шанс',\n",
       "  'подарок',\n",
       "  'выше',\n",
       "  'котрый',\n",
       "  'никто',\n",
       "  'спросить',\n",
       "  'хороший',\n",
       "  'отдать',\n",
       "  'хотяб',\n",
       "  '500',\n",
       "  'благотворительность',\n",
       "  'дабы',\n",
       "  'спугнуть',\n",
       "  'удача'],\n",
       " ['эбу',\n",
       "  'двенашка',\n",
       "  'называться',\n",
       "  'итэлма',\n",
       "  'эбу',\n",
       "  'эбу',\n",
       "  '—',\n",
       "  'электронный',\n",
       "  'блок',\n",
       "  'управление',\n",
       "  'двигатель',\n",
       "  'автомобиль',\n",
       "  'название',\n",
       "  '—',\n",
       "  'контроллер',\n",
       "  'принимать',\n",
       "  'информация',\n",
       "  'датчик',\n",
       "  'обрабатывать',\n",
       "  'особый',\n",
       "  'алгоритм',\n",
       "  'отталкиваться',\n",
       "  'получить',\n",
       "  'данные',\n",
       "  'отдавать',\n",
       "  'команда',\n",
       "  'исполнительный',\n",
       "  'устройство',\n",
       "  'система'],\n",
       " ['академия',\n",
       "  'вампир',\n",
       "  'даный',\n",
       "  'момент',\n",
       "  'часть',\n",
       "  'книга',\n",
       "  'академия',\n",
       "  'вампир',\n",
       "  '4',\n",
       "  'охотник',\n",
       "  'жертва',\n",
       "  'ледяной',\n",
       "  'укус',\n",
       "  'поцелуй',\n",
       "  'тьма',\n",
       "  'кровный',\n",
       "  'клятва'],\n",
       " ['защититься',\n",
       "  'энергетический',\n",
       "  'вампир',\n",
       "  'защита',\n",
       "  'мысль',\n",
       "  'brкаждый',\n",
       "  'должный',\n",
       "  'отношение',\n",
       "  'вампир',\n",
       "  'взять',\n",
       "  'правило',\n",
       "  'страшный',\n",
       "  'серый',\n",
       "  'волк',\n",
       "  'знать',\n",
       "  'конкретный',\n",
       "  'серый',\n",
       "  'волк',\n",
       "  'вампир',\n",
       "  'существовать',\n",
       "  'воспринимать',\n",
       "  'следовать',\n",
       "  'хищник',\n",
       "  'добрый',\n",
       "  'домашний',\n",
       "  'собачка',\n",
       "  'собачка',\n",
       "  'быстро',\n",
       "  'почувствовать',\n",
       "  'поле',\n",
       "  'ягода',\n",
       "  'быстро',\n",
       "  'отстать',\n",
       "  'brвитание',\n",
       "  'облако',\n",
       "  'brтожий',\n",
       "  'хороший',\n",
       "  'способ',\n",
       "  'мысленно',\n",
       "  'представить',\n",
       "  'находиться',\n",
       "  'окружение',\n",
       "  'приятный',\n",
       "  'ощущение',\n",
       "  'белый',\n",
       "  'облако',\n",
       "  'синеголубой',\n",
       "  'небо',\n",
       "  'эффективно',\n",
       "  'brподкормка',\n",
       "  'негатив',\n",
       "  'brвампир',\n",
       "  'кушать',\n",
       "  'дать',\n",
       "  'собрать',\n",
       "  'плохой',\n",
       "  'мысль',\n",
       "  'эмоция',\n",
       "  'отрицательный',\n",
       "  'какимтый',\n",
       "  'образ',\n",
       "  'закрасться',\n",
       "  'организм',\n",
       "  'тяжесть',\n",
       "  'отдать',\n",
       "  'вампир',\n",
       "  'пусть',\n",
       "  'подавиться',\n",
       "  'brзеркало',\n",
       "  'brпереть',\n",
       "  'встреча',\n",
       "  'общение',\n",
       "  'неприятный',\n",
       "  'мысленно',\n",
       "  'представить',\n",
       "  'зеркальный',\n",
       "  'стена',\n",
       "  'обратить',\n",
       "  'отражать',\n",
       "  'поверхность',\n",
       "  'brдикобраз',\n",
       "  'brэтота',\n",
       "  'способ',\n",
       "  'выглядеть',\n",
       "  'следующий',\n",
       "  'образ',\n",
       "  'почувствовать',\n",
       "  'опасность',\n",
       "  'мысленно',\n",
       "  'покрывать',\n",
       "  'свой',\n",
       "  'биополе',\n",
       "  'игла',\n",
       "  'шип',\n",
       "  'энергетический',\n",
       "  'вампир',\n",
       "  'попробовать',\n",
       "  'высосать',\n",
       "  'биоэнергия',\n",
       "  'ощущать',\n",
       "  'боль',\n",
       "  'прикосновение',\n",
       "  'биополе',\n",
       "  'brзамыкание',\n",
       "  'контур',\n",
       "  'биополе',\n",
       "  'br',\n",
       "  'brсуществовать',\n",
       "  'способ',\n",
       "  'выбирать',\n",
       "  'удобный',\n",
       "  'способ',\n",
       "  'заключаться',\n",
       "  'скрещивание',\n",
       "  'нога',\n",
       "  'рука',\n",
       "  'общение',\n",
       "  'ждать',\n",
       "  'неприятность',\n",
       "  'способ',\n",
       "  'заключаться',\n",
       "  'следующий',\n",
       "  'большой',\n",
       "  'указательный',\n",
       "  'палец',\n",
       "  'рука',\n",
       "  'соединить',\n",
       "  'больший',\n",
       "  'указательный',\n",
       "  'палец',\n",
       "  'рука',\n",
       "  'образовать',\n",
       "  'кольцо',\n",
       "  'остальной',\n",
       "  'палец',\n",
       "  'рука',\n",
       "  'наложить',\n",
       "  'друг',\n",
       "  'друг',\n",
       "  'способ',\n",
       "  'эффективный',\n",
       "  'благодаря',\n",
       "  'замыкаться',\n",
       "  'контур',\n",
       "  'биополе',\n",
       "  'оставлять',\n",
       "  'пробоина',\n",
       "  'энергетический',\n",
       "  'вампир',\n",
       "  'пробиться',\n",
       "  'защита',\n",
       "  'вытянуть',\n",
       "  'биоэнергия',\n",
       "  'br',\n",
       "  'brвсе',\n",
       "  'приём',\n",
       "  'делать',\n",
       "  'незаметно',\n",
       "  'демонстрировать',\n",
       "  'свой',\n",
       "  'действие',\n",
       "  'привлекать',\n",
       "  'внимание',\n",
       "  'окружающий'],\n",
       " ['выращивать',\n",
       "  'магнолия',\n",
       "  'открытый',\n",
       "  'грунт',\n",
       "  'средний',\n",
       "  'полоса',\n",
       "  'россия',\n",
       "  'вид',\n",
       "  'сорт',\n",
       "  'зимовать',\n",
       "  'укрытие',\n",
       "  'укрытие',\n",
       "  'цвести',\n",
       "  'магнолия',\n",
       "  'каков',\n",
       "  'размер',\n",
       "  'дерево',\n",
       "  'особенность',\n",
       "  'выращивание',\n",
       "  'указывать',\n",
       "  'ответ',\n",
       "  'регион',\n",
       "  'прикреплять',\n",
       "  'фотой',\n",
       "  'выращивать',\n",
       "  'хабаровск',\n",
       "  'дв',\n",
       "  'brв',\n",
       "  'кратец',\n",
       "  'прочитать',\n",
       "  'сайт',\n",
       "  'метод',\n",
       "  'выращивание',\n",
       "  'магнолия',\n",
       "  'средний',\n",
       "  'полоса',\n",
       "  'купить',\n",
       "  'черенок',\n",
       "  'растение',\n",
       "  '34',\n",
       "  'выращиваться',\n",
       "  'кадочный',\n",
       "  'растение',\n",
       "  'роза',\n",
       "  'лето',\n",
       "  'улица',\n",
       "  'зима',\n",
       "  'погреб',\n",
       "  'прохладный',\n",
       "  'помещение',\n",
       "  'тип',\n",
       "  'холодильник',\n",
       "  'весна',\n",
       "  'весна',\n",
       "  'сад',\n",
       "  'нарастить',\n",
       "  'мощный',\n",
       "  'корневой',\n",
       "  'система',\n",
       "  '34',\n",
       "  'высаживать',\n",
       "  'грунт',\n",
       "  'зима',\n",
       "  'укрывать',\n",
       "  'возможность',\n",
       "  'brмоя',\n",
       "  '1',\n",
       "  'растить',\n",
       "  'brсорт',\n",
       "  'магнолия',\n",
       "  'susanbr'],\n",
       " ['отформатировать',\n",
       "  'диск',\n",
       "  'c',\n",
       "  'дос',\n",
       "  'формат',\n",
       "  'ntfs',\n",
       "  'команда',\n",
       "  'fdisk',\n",
       "  'жёсткий',\n",
       "  'диск',\n",
       "  'найти',\n",
       "  'скачать',\n",
       "  'программа',\n",
       "  'акронис',\n",
       "  'диск',\n",
       "  'директор',\n",
       "  'загрузочный',\n",
       "  'версия'],\n",
       " ['относиться',\n",
       "  'парикмахер',\n",
       "  'работать',\n",
       "  'дом',\n",
       "  'помешать',\n",
       "  'например',\n",
       "  'присутствие',\n",
       "  'дом',\n",
       "  'ребёнок',\n",
       "  'муж',\n",
       "  'нормально',\n",
       "  'мыть',\n",
       "  'голова',\n",
       "  'ванная',\n",
       "  'ракомести',\n",
       "  'профессионал',\n",
       "  'нетглавное',\n",
       "  'остаться',\n",
       "  'довольный',\n",
       "  'результатомситуация',\n",
       "  'разный',\n",
       "  'бываютмочь',\n",
       "  'мамочка',\n",
       "  'декретемочь',\n",
       "  'выгодный',\n",
       "  'работать',\n",
       "  'себябез',\n",
       "  'аренда',\n",
       "  'вкусностейд',\n",
       "  'правило',\n",
       "  'цена',\n",
       "  'услуга',\n",
       "  'нижеа',\n",
       "  'общение',\n",
       "  'свободнейможный',\n",
       "  'получить',\n",
       "  'хороший',\n",
       "  'друг',\n",
       "  'собеседник'],\n",
       " ['кошка', 'олег', 'видеть', '♦•давно', 'олег', 'стать', 'котом•♦'],\n",
       " ['пьяный',\n",
       "  'везти',\n",
       "  'большой',\n",
       "  'трезвый',\n",
       "  'бог',\n",
       "  'русь',\n",
       "  'беречь',\n",
       "  'пьяный',\n",
       "  'дурак']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences = sentences[:50_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zwXvXkJBVJ0B"
   },
   "outputs": [],
   "source": [
    "# Обучим модель FastText - но только на датасете Болталки (добавить продуктовый датасет)\n",
    "\n",
    "file_path_from = 'ft_model'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "    sentences = [i for i in tqdm(sentences) if len(i) > 2]\n",
    "    modelFT = FastText(sentences=sentences, size=100, min_count=1, window=5)\n",
    "    modelFT.save(\"ft_model\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить модель\n",
    "\n",
    "modelFT = FastText.load(\"ft_model\")\n",
    "ft_index = annoy.AnnoyIndex(100 ,'angular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Размерность вектора модели_. Если установить 100 — каждое слово в корпусе будет представлено в виде 100-мерного вектора, и т.д.\n",
    "\n",
    "_Наименьшее допустимое количество символов в слове_, для которого будет создаваться векторное представление; так можно убрать частотные, но не очень значимые слова типа союзов и предлогов.\n",
    "\n",
    "_Размер окна_. Этот параметр задаёт, сколько соседних слов считается частью контекста. Если выставить 50, то алгоритм возьмёт 50 слов спереди от слова и 50 слов сзади от слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['семь',\n",
       " 'кругом',\n",
       " 'другой',\n",
       " 'её',\n",
       " 'самого',\n",
       " 'всюду',\n",
       " 'лучше',\n",
       " 'который',\n",
       " 'твоё',\n",
       " 'восемнадцатый',\n",
       " 'буду',\n",
       " 'наверху',\n",
       " 'во',\n",
       " 'после',\n",
       " 'нет',\n",
       " 'чего',\n",
       " 'своего',\n",
       " 'одной',\n",
       " 'но',\n",
       " 'с']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(get_stop_words(\"ru\")))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем Индексы для вопросов-ответов\n",
    "\n",
    "file_path_from = 'speaker.ann'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    morpher = MorphAnalyzer()\n",
    "    sw = set(get_stop_words(\"ru\"))\n",
    "    exclude = set(string.punctuation)\n",
    "    modelFT = FastText.load(\"ft_model\")\n",
    "    ft_index = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    index_map = {}\n",
    "    counter = 0\n",
    "    with open(\"Otvety2.txt\", \"r\") as f:\n",
    "        for line in tqdm(f):\n",
    "            n_ft = 0\n",
    "            spls = line.split(\"===\")\n",
    "            index_map[counter] = spls[1]\n",
    "            question = preprocess_txt(spls[0])\n",
    "            vector_ft = np.zeros(100)\n",
    "            for word in question:\n",
    "                if word in modelFT.wv:\n",
    "                    vector_ft += modelFT.wv[word]\n",
    "                    n_ft += 1\n",
    "            if n_ft > 0:\n",
    "                vector_ft = vector_ft / n_ft\n",
    "            ft_index.add_item(counter, vector_ft)\n",
    "            counter += 1\n",
    "\n",
    "            if counter > 50_000:\n",
    "                break\n",
    "\n",
    "    ft_index.build(10)\n",
    "    ft_index.save('speaker.ann')\n",
    "    \n",
    "    with open(\"index_speaker.pkl\", \"wb\") as f:\n",
    "        pickle.dump(index_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ofHcj4W8VJ0E",
    "outputId": "f40f185c-ae76-4c53-c08f-5428d1745c7b"
   },
   "outputs": [],
   "source": [
    "#  Загрузим индексы\n",
    "ft_index = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index.load('speaker.ann')\n",
    "index_map = pd.read_pickle(\"index_speaker.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 69,  8, 25, 99, 77, 98, 63, 17, 45, 92, 26, 57, 67, 14, 29, 31,\n",
       "       55, 61, 33,  4, 68, 51, 65, 44,  1, 59, 97, 50, 22, 19, 13, 96, 87,\n",
       "       42, 38, 80,  6, 41, 47, 76, 28, 30,  0, 53, 66, 23, 16, 34, 49, 18,\n",
       "       74, 75, 24, 90, 88, 62, 58, 35, 10, 84, 40, 73, 27, 82, 60, 72, 64,\n",
       "       85, 15, 52, 89, 48, 43, 79,  2, 83, 93, 46, 95, 86, 20, 21, 70,  3,\n",
       "       39, 11, 32,  5, 81, 78, 56, 91, 36,  9, 12, 54, 71, 37, 94])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.permutation(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "b9DvlLGVVJ0F",
    "outputId": "27a213d5-372d-428b-de89-0b1f19af8a73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([44775, 21479, 2636, 8453, 47871],\n",
       " [1.2995293140411377,\n",
       "  1.309201955795288,\n",
       "  1.3144482374191284,\n",
       "  1.3213552236557007,\n",
       "  1.3229308128356934])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Пример получения индексов\n",
    "a = ft_index.get_nns_by_vector(np.random.permutation(100), 5, include_distances=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['хиииия мышакрыс.\\n',\n",
       " 'живить -как умеешь..\\n',\n",
       " '<p>ль сян (79 н. э. — 6 н. э.) — выдающийся китайский историк, текстолог, знаток старинный канон династия ранний хань. </p> <h2>биография</h2> <p>родиться сюйчжоу семье, родственный дружеский отношение представитель династия хань. потомок лю цзяо, младший брат лю бана, основатель династии. юность переезжать чанъян, учиться тая сюэ, императорский академии. получить превосходный образование. лю составить каталог императорский библиотека (вейлу), заниматься редактирование канонов. получить сановный титул дафу. 56 н. э. больший труд избежать смертный казни, вследствие неудачный алхимический попытка сделать золото. 26 н. э. император чэн-ди назначить лю сянить хранитель императорский библиотеки. должность наладить работа библиотеки. разработать канонический формат классический текстов, стать норма протяжение последующий веков. оставаться советник император династия хань, пытаться предотвратить влияние императрица ван. скончаться лю сян столица 6 н. э. дело продолжить сын лю синь. </p> <h2>творчество</h2> <p>ль сян редактор шаня хай цзин, «сюань-цзы», «история сада». составить исторический произведение «жизнеописание знаменитый женщин» (расположить группа «звёздный матери», «милостивый мудрые», «девственник смиренные», «красноречивый умные», «грешный легкое») «жизнеописание выдающийся бессмертных». </p> <h2>источники</h2> <ul> <li>leeuw, karel van der, het chinese denken. geschiedenis van de chinese filosofie in hoofdlijnen, amsterdam (boom) 1994, isbn 90-5352-088-0, гг. 149-150.</li> <li>fei, zhengang, \"liu xiang\". encyclopedia of china (philosophy edition), 1st ed.</li> <li>hawkes, david, translator and introduction (2011 [1985]). qu yuan et al., the songs of the south: an ancient chinese anthology of poems by qu yuan and other poets. london: penguin books. isbn 978-0-14-044375-2</li> <li>loewe, michael. (1986). \"the former han dynasty,\" in the cambridge history of china: volume i: the ch\\'in and han empires, 221 b.c. – a.d. 220, 103–222. edited by denis twitchett and michael loewe. cambridge: cambridge university press. isbn 0-521-24327-0.</li> <li>liexian zhuan (biographies des immortels célèbres), trad. max kaltenmark : le lie-sien tchouan, pékin, 1953 ; rééd. institut des hautes études chinoises, 1987.</li> <li>lienü zhuan (biographies des femmes célèbres), trad. an. : exemplary women of early china. the lienü zhuan of liu xiang, trad. anne behnke kinney, new york, columbia university press, 2014.</li> <li>christofer schipper, recherches sur le taoïsme ancien</li></ul> <h2>примечания</h2>.\\n',\n",
       " 'любовь есть, секса, сожалению, ненадолго....\\n',\n",
       " 'доверие!!!!.\\n']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[index_map[x] for x in a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gbcdn.mrgcdn.ru/uploads/asset/5209459/attachment/1b2f5aa57ff77e7c2d2ee26ceb09eb9e.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Z-qxfw70VJ0G",
    "outputId": "d9ad78f5-5ed3-4690-e5d4-2d05ba34155c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684dc227bfa3431cac4053d230329990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>descrirption</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>properties</th>\n",
       "      <th>image_links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Юбка детская ORBY</td>\n",
       "      <td>Новая, не носили ни разу. В реале красивей чем...</td>\n",
       "      <td>58e3cfe6132ca50e053f5f82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2211</td>\n",
       "      <td>{'detskie_razmer_rost': '81-86 (1,5 года)'}</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/58...</td>\n",
       "      <td>[юбка, детский, orby, новый, носить, реал, кра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ботильоны</td>\n",
       "      <td>Новые,привезены из Чехии ,указан размер 40,но ...</td>\n",
       "      <td>5667531b2b7f8d127d838c34</td>\n",
       "      <td>9.0</td>\n",
       "      <td>902</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5b...</td>\n",
       "      <td>[ботильон, новыепривезти, чехия, указать, разм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Брюки</td>\n",
       "      <td>Размер 40-42. Брюки почти новые - не знаю как ...</td>\n",
       "      <td>59534826aaab284cba337e06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>906</td>\n",
       "      <td>{'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/59...</td>\n",
       "      <td>[брюки, размер, 4042, брюки, новый, знать, мер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продам детские шапки</td>\n",
       "      <td>Продам шапки,кажда 200р.Розовая и белая проданны.</td>\n",
       "      <td>57de544096ad842e26de8027</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2217</td>\n",
       "      <td>{'detskie_pol': 'Девочкам', 'detskaya_odezhda_...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/57...</td>\n",
       "      <td>[продать, детский, шапка, продать, шапкикажда,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Блузка</td>\n",
       "      <td>Темно-синяя, 42 размер,состояние отличное,как ...</td>\n",
       "      <td>5ad4d2626c86cb168d212022</td>\n",
       "      <td>9.0</td>\n",
       "      <td>907</td>\n",
       "      <td>{'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...</td>\n",
       "      <td>http://cache3.youla.io/files/images/360_360/5a...</td>\n",
       "      <td>[блузка, темносиний, 42, размерсостояние, отли...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                       descrirption  \\\n",
       "0     Юбка детская ORBY  Новая, не носили ни разу. В реале красивей чем...   \n",
       "1             Ботильоны  Новые,привезены из Чехии ,указан размер 40,но ...   \n",
       "2                 Брюки  Размер 40-42. Брюки почти новые - не знаю как ...   \n",
       "3  Продам детские шапки  Продам шапки,кажда 200р.Розовая и белая проданны.   \n",
       "4                Блузка  Темно-синяя, 42 размер,состояние отличное,как ...   \n",
       "\n",
       "                 product_id  category_id subcategory_id  \\\n",
       "0  58e3cfe6132ca50e053f5f82         22.0           2211   \n",
       "1  5667531b2b7f8d127d838c34          9.0            902   \n",
       "2  59534826aaab284cba337e06          9.0            906   \n",
       "3  57de544096ad842e26de8027         22.0           2217   \n",
       "4  5ad4d2626c86cb168d212022          9.0            907   \n",
       "\n",
       "                                          properties  \\\n",
       "0        {'detskie_razmer_rost': '81-86 (1,5 года)'}   \n",
       "1  {'zhenskaya_odezhda_tzvet': 'Зеленый', 'visota...   \n",
       "2  {'zhenskaya_odezhda_dzhinsy_bryuki_tip': 'Брюк...   \n",
       "3  {'detskie_pol': 'Девочкам', 'detskaya_odezhda_...   \n",
       "4  {'zhenskaya_odezhda_tzvet': 'Синий', 'zhenskay...   \n",
       "\n",
       "                                         image_links  \\\n",
       "0  http://cache3.youla.io/files/images/360_360/58...   \n",
       "1  http://cache3.youla.io/files/images/360_360/5b...   \n",
       "2  http://cache3.youla.io/files/images/360_360/59...   \n",
       "3  http://cache3.youla.io/files/images/360_360/57...   \n",
       "4  http://cache3.youla.io/files/images/360_360/5a...   \n",
       "\n",
       "                                                text  \n",
       "0  [юбка, детский, orby, новый, носить, реал, кра...  \n",
       "1  [ботильон, новыепривезти, чехия, указать, разм...  \n",
       "2  [брюки, размер, 4042, брюки, новый, знать, мер...  \n",
       "3  [продать, детский, шапка, продать, шапкикажда,...  \n",
       "4  [блузка, темносиний, 42, размерсостояние, отли...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим модель продуктовых данных\n",
    "\n",
    "shop_data = pd.read_csv(\"ProductsDataset.csv\")\n",
    "#shop_data = shop_data.iloc[:5000, :]\n",
    "\n",
    "shop_data['text'] = shop_data['title'] + \" \" + shop_data[\"descrirption\"]\n",
    "shop_data['text'] = shop_data['text'].progress_apply(lambda x: preprocess_txt(str(x)))\n",
    "shop_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "rqml_x5JVJ0H"
   },
   "outputs": [],
   "source": [
    "# Подготовка для создания модели для определения домена данных\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Xfxh1xO9VJ0I"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad958659ae0f4d23a6d4d3631e8b5c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134905d89fc24fb183d9ca6b1f6f6c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idxs = set(np.random.randint(0, len(index_map), len(shop_data)))\n",
    "# Вопрос-ответный домен\n",
    "negative_texts = [\" \".join(preprocess_txt(index_map[i])) for i in tqdm(idxs)]\n",
    "# Продуктовый домен\n",
    "positive_texts = [\" \".join(val) for val in tqdm(shop_data['text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3ud68payVJ0J"
   },
   "outputs": [],
   "source": [
    "# ВО = 0, Прод = 1\n",
    "\n",
    "dataset = negative_texts + positive_texts\n",
    "labels = np.zeros(len(dataset))\n",
    "labels[len(negative_texts):] = np.ones(len(positive_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "N_oxnOuzVJ0K"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, labels, test_size=0.2, \n",
    "                                                    stratify=labels, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tNzqfsIZVJ0K",
    "outputId": "d3173275-3a00-47e2-8243-372f61a627c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmv/anaconda3/envs/nlp39/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Модель\n",
    "\n",
    "vectorizer.fit(dataset)\n",
    "\n",
    "x_train_vec = vectorizer.transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression().fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "q_bWwksAVJ0L",
    "outputId": "e410d691-e516-45aa-ac0e-d8ef0378cc4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9785456927612185"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true=y_test, y_pred=lr.predict(x_test_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23VbtYIiVJ0M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим IDF взвешивание (для каждого слова найдем IDF вес)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "XFgbubh7VJ0N"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "yx8AkUiiVJ0N",
    "outputId": "dce321cc-2846-4c1c-a42e-c6aff189837e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.771512604778932"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_vect.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "aQQG_bluVJ0O",
    "outputId": "90701b9a-a491-417a-a291-fc3209df90fb"
   },
   "outputs": [],
   "source": [
    "idfs = {v[0]: v[1] for v in zip(tfidf_vect.vocabulary_, tfidf_vect.idf_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149431"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['брюки', 'женский', 'утеплить', 'демисезонный', 'длина']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.157370441186774,\n",
       " 6.9443975068824155,\n",
       " 11.103280590242088,\n",
       " 11.103280590242088,\n",
       " 11.103280590242088]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(idfs.values())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "9ae8735faac34a36be98a6d1f1fcd62e"
     ]
    },
    "id": "JjWyFjJBVJ0P",
    "outputId": "69c1e269-b020-4542-9b84-812cc5485b08"
   },
   "outputs": [],
   "source": [
    "# Создаем Индексы для продуктовых данных\n",
    "\n",
    "file_path_from = 'shop.ann'\n",
    "if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "    \n",
    "    ft_index_shop = annoy.AnnoyIndex(100 ,'angular')\n",
    "\n",
    "    midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "    index_map_shop = {}\n",
    "    counter = 0\n",
    "\n",
    "    for i in tqdm(range(len(shop_data))):\n",
    "        n_ft = 0\n",
    "        index_map_shop[counter] = (shop_data.loc[i, \"title\"], shop_data.loc[i, \"image_links\"])\n",
    "        vector_ft = np.zeros(100)\n",
    "        for word in shop_data.loc[i, \"text\"]:\n",
    "            if word in modelFT.wv:\n",
    "                vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "                n_ft += idfs.get(word, midf)\n",
    "        if n_ft > 0:\n",
    "            vector_ft = vector_ft / n_ft\n",
    "        ft_index_shop.add_item(counter, vector_ft)\n",
    "        counter += 1\n",
    "\n",
    "    ft_index_shop.build(10)\n",
    "    ft_index_shop.save('shop.ann')\n",
    "\n",
    "    file_path_from = 'index_shop.pkl'\n",
    "    if not os.path.isfile(file_path_from):  \n",
    "    \n",
    "        with open(\"index_shop.pkl\", \"wb\") as f:\n",
    "            pickle.dump(index_map_shop, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим индексы\n",
    "\n",
    "midf = np.mean(tfidf_vect.idf_)\n",
    "\n",
    "ft_index_shop = annoy.AnnoyIndex(100, 'angular')\n",
    "ft_index_shop.load('shop.ann') \n",
    "\n",
    "index_map_shop = pd.read_pickle(\"index_shop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iwnz2qFTVJ0Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "47tviu39VJ0Q"
   },
   "outputs": [],
   "source": [
    "# Основная функция преобразования текста в вектор х100\n",
    "\n",
    "def embed_txt(txt, idfs, midf):\n",
    "    n_ft = 0\n",
    "    vector_ft = np.zeros(100)\n",
    "    for word in txt:\n",
    "        if word in modelFT.wv:\n",
    "            vector_ft += modelFT.wv[word] * idfs.get(word, midf)\n",
    "            n_ft += idfs.get(word, midf)\n",
    "    return vector_ft / n_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "H3jf5wMsVJ0R",
    "outputId": "d6f9717b-3d10-472e-bc27-893bf19f21bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([15196, 31675, 23970, 28535, 13733],\n",
       " [1.3877694606781006,\n",
       "  1.4109797477722168,\n",
       "  1.411629319190979,\n",
       "  1.411629319190979,\n",
       "  1.4125539064407349])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример получения индекса\n",
    "\n",
    "ft_index_shop.get_nns_by_vector(np.ones(100)*20, 5, include_distances=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание своего бота в телеграмм\n",
    "# @botfather\n",
    "# /start\n",
    "# /newbot - create a new bot\n",
    "# name1\n",
    "# name1_BOT\n",
    "#. ->. API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "B3sxuG-hVJ0S",
    "outputId": "e61e1613-8860-4e1a-814a-eda3f75bd6ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r3/cl7lvwsx1j9d57z0wgwk1h380000gn/T/ipykernel_24111/2641577093.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  return vector_ft / n_ft\n"
     ]
    }
   ],
   "source": [
    "# заменить на свой токен\n",
    "updater = Updater(\"6768256083:AAG3-ltpwsaMg27yy8Xgq9dkHJlt_LU9AJY\", use_context=True) # Токен API к Telegram\n",
    "dispatcher = updater.dispatcher\n",
    "\n",
    "def startCommand(update, context):\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text='Привет, давай пообщаемся?')\n",
    "\n",
    "def textMessage(update, context):\n",
    "    \n",
    "    input_txt = preprocess_txt(update.message.text)\n",
    "    vect = vectorizer.transform([\" \".join(input_txt)])\n",
    "    prediction = lr.predict(vect)\n",
    "    \n",
    "    # ПРОД\n",
    "    if prediction[0] == 1:\n",
    "        vect_ft = embed_txt(input_txt, idfs, midf)\n",
    "        ft_index_shop_val = ft_index_shop.get_nns_by_vector(vect_ft, 5)\n",
    "        for item in ft_index_shop_val:\n",
    "            title, image = index_map_shop[item]\n",
    "            context.bot.send_message(chat_id=update.message.chat_id, text=\"title: {} image: {}\".format(title, image))\n",
    "        return\n",
    "    \n",
    "    # QA\n",
    "    vect_ft = embed_txt(input_txt, {}, 1)\n",
    "    ft_index_val, distances = ft_index.get_nns_by_vector(vect_ft, 1, include_distances=True)\n",
    "    print(distances[0])\n",
    "    \n",
    "    # \n",
    "    if distances[0] > 10000.5:\n",
    "        print(distances[0])\n",
    "        context.bot.send_message(chat_id=update.message.chat_id, text=\"Не понимаю\")\n",
    "        return\n",
    "    \n",
    "    # Вопрос-Ответ\n",
    "    context.bot.send_message(chat_id=update.message.chat_id, text=index_map[ft_index_val[0]])\n",
    "        \n",
    "start_command_handler = CommandHandler('start', startCommand)\n",
    "text_message_handler = MessageHandler(Filters.text, textMessage)\n",
    "dispatcher.add_handler(start_command_handler)\n",
    "dispatcher.add_handler(text_message_handler)\n",
    "updater.start_polling(clean=True)\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://github.com/Koziev/NLP_Datasets\n",
    "# https://github.com/natasha/corus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m venv ~/.venvs/natasha-corus\n",
    "# source ~/.venvs/natasha-corus/bin/activate\n",
    "\n",
    "# pip install -r requirements/dev.txt\n",
    "# pip install -e .\n",
    "\n",
    "# python -m ipykernel install --user --name natasha-corus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Получение сообщений от пользователя\n",
    "@bot.message_handler(content_types=[\"text\"])\n",
    "def handle_text(message):\n",
    "   \n",
    "    global GM_Bot_Flag    \n",
    "    # bot.send_message(message.chat.id, str(GM_Bot_Flag))\n",
    "\n",
    "    if message.text.lower() == 'привет': GM_Bot_Flag = 0\n",
    "    \n",
    "\n",
    "    if GM_Bot_Flag == 0:# or message.text == 'Назад':\n",
    "        # Готовим кнопки\n",
    "        keyboard = types.InlineKeyboardMarkup()\n",
    "        # И добавляем кнопку на экран\n",
    "        key_oven = types.InlineKeyboardButton(text='Медицинская болталка', callback_data='Медицинская болталка')\n",
    "        # И добавляем кнопку на экран\n",
    "        keyboard.add(key_oven)\n",
    "        key_telec = types.InlineKeyboardButton(text='ChatGpt', callback_data='ChatGpt')\n",
    "        keyboard.add(key_telec)\n",
    "        # Показываем все кнопки сразу и пишем сообщение о выборе\n",
    "        bot.send_message(message.chat.id, text='Сделайте выбор', reply_markup=keyboard)\n",
    "    \n",
    "    elif GM_Bot_Flag == 1:\n",
    "        answer = \"Ответ Медицинской болталки: \" + babbler(message.text)\n",
    "        bot.send_message(message.chat.id, answer)\n",
    "        # print(answer)\n",
    "        # bot.send_message(message.chat.id, babbler(message.text))\n",
    "    \n",
    "    elif GM_Bot_Flag == 2:\n",
    "        answer =  \"Ответ ChatGPT: \" + askChatGPT(message.text)\n",
    "        bot.send_message(message.chat.id, answer)\n",
    "        # print(answer)\n",
    " \n",
    "\n",
    "# Запускаем бота\n",
    "bot.polling(none_stop=True, interval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph=pymorphy2.MorphAnalyzer()\n",
    "import numpy as np\n",
    "import datetime\n",
    "random_state = 17\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle as pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "%config InlineBackend.figure_format = 'svg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_full = data_all['process']\n",
    "y_full = data_all['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, \n",
    "                                                    y_full,\n",
    "                                                    train_size=0.80, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify = y_full)\n",
    "\n",
    "vectorizer=TfidfVectorizer(analyzer='word', \n",
    "                           lowercase=False, \n",
    "                           ngram_range=(1, 3), \n",
    "                           min_df=0.0005, \n",
    "                           max_df=0.995, \n",
    "                           max_features = None)\n",
    "\n",
    "X_full = vectorizer.fit_transform(X_full)\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "features = vectorizer.get_feature_names()\n",
    "print(\"Количество признаков {}\".format(X_train.shape[1]))\n",
    "# 11130\n",
    "class_names = sorted(np.unique(y_full))\n",
    "weights = [1 for i in range(0,len(class_names))]\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    weights[i] = len(y_full[y_full == class_names[i]])*100.0/len(y_full)\n",
    "\n",
    "class_weight=dict(zip(class_names, weights))\n",
    "\n",
    "name = 'Logistic Regression'\n",
    "clf_default = LogisticRegression(random_state=random_state, n_jobs=-1)\n",
    "params = {'penalty' : ['l2'],\n",
    "          'tol': [1e-2,1e-1],\n",
    "          'C': [x for x in range(10, 21, 2)],\n",
    "          'fit_intercept': (True, False),\n",
    "          'class_weight': ['balanced', None, class_weight],\n",
    "          'multi_class' : ['ovr'],\n",
    "          'solver': ['sag'],\n",
    "          'max_iter' : (5,7,9,11,15,21)\n",
    "           }\n",
    "\n",
    "start_time = datetime.datetime.now() \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "clf = GridSearchCV(clf_default, params, cv=skf, n_jobs=-1, verbose = 10, error_score = 0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(datetime.datetime.now() - start_time)\n",
    "best_clf = clf.best_estimator_\n",
    "print(clf.best_score_)\n",
    "print(best_clf)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "cv_score = cross_val_score(best_clf, X_train, y_train, cv = skf, n_jobs=-1)\n",
    "print('cv_score.mean', cv_score.mean())\n",
    "y_pred = best_clf.predict(X_test)\n",
    "print ( 'Accuracy test', accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, best_clf.predict(X_test))\n",
    "np.set_printoptions(precision=2)\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix test')\n",
    "fig.savefig('lr_test1.jpg')\n",
    "\n",
    "y_pred = best_clf.predict(X_full)\n",
    "data_all['Class1'] = y_pred\n",
    "mistake = [compare(data_all['Class'][x], data_all['Class1'][x]) for x in range(len(data_all))]\n",
    "print(np.sum(mistake)/len(mistake))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lesson_16.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
